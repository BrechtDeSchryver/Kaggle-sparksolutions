{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import numpy as np\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jarno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-1O6Q1L2I:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spaceship_rescue</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1713fcc9f00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Spaceship_rescue\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'train.csv'\n",
    "test_data = 'test.csv'\n",
    "df_train = spark.read.csv(train_data, header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(test_data, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in train data:  4446966\n"
     ]
    }
   ],
   "source": [
    "# get total number of rows\n",
    "print(\"Total number of rows in train data: \", df_train.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kolommen die ik niet ga gebruiken\n",
    "df_train = df_train.drop('Id')\n",
    "df_train = df_train.drop('groupId')\n",
    "df_train = df_train.drop('matchId')\n",
    "df_train = df_train.drop('matchType')\n",
    "\n",
    "df_test = df_test.drop('Id')\n",
    "df_test = df_test.drop('groupId')\n",
    "df_test = df_test.drop('matchId')\n",
    "df_test = df_test.drop('matchType')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+-----+-------------+-----+---------+----------+-----+-----------+-----------+-------------+--------+---------+----------+-------+------------+---------+------------+---------+---------------+------------+---------------+---------+------------+\n",
      "|assists|boosts|damageDealt|DBNOs|headshotKills|heals|killPlace|killPoints|kills|killStreaks|longestKill|matchDuration|maxPlace|numGroups|rankPoints|revives|rideDistance|roadKills|swimDistance|teamKills|vehicleDestroys|walkDistance|weaponsAcquired|winPoints|winPlacePerc|\n",
      "+-------+------+-----------+-----+-------------+-----+---------+----------+-----+-----------+-----------+-------------+--------+---------+----------+-------+------------+---------+------------+---------+---------------+------------+---------------+---------+------------+\n",
      "|      0|     0|          0|    0|            0|    0|        0|         0|    0|          0|          0|            0|       0|        0|         0|      0|           0|        0|           0|        0|              0|           0|              0|        0|           1|\n",
      "+-------+------+-----------+-----+-------------+-----+---------+----------+-----+-----------+-----------+-------------+--------+---------+----------+-------+------------+---------+------------+---------+---------------+------------+---------------+---------+------------+\n",
      "\n",
      "Total number of null values in each column:  None\n"
     ]
    }
   ],
   "source": [
    "# get total number of null values in each column\n",
    "print(\"Total number of null values in each column: \", df_train.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df_train.columns]).show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('assists', 'int'),\n",
       " ('boosts', 'int'),\n",
       " ('damageDealt', 'double'),\n",
       " ('DBNOs', 'int'),\n",
       " ('headshotKills', 'int'),\n",
       " ('heals', 'int'),\n",
       " ('killPlace', 'int'),\n",
       " ('killPoints', 'int'),\n",
       " ('kills', 'int'),\n",
       " ('killStreaks', 'int'),\n",
       " ('longestKill', 'double'),\n",
       " ('matchDuration', 'int'),\n",
       " ('maxPlace', 'int'),\n",
       " ('numGroups', 'int'),\n",
       " ('rankPoints', 'int'),\n",
       " ('revives', 'int'),\n",
       " ('rideDistance', 'double'),\n",
       " ('roadKills', 'int'),\n",
       " ('swimDistance', 'double'),\n",
       " ('teamKills', 'int'),\n",
       " ('vehicleDestroys', 'int'),\n",
       " ('walkDistance', 'double'),\n",
       " ('weaponsAcquired', 'int'),\n",
       " ('winPoints', 'int'),\n",
       " ('winPlacePerc', 'double')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with null values\n",
    "df_train = df_train.na.drop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills', 'killStreaks', 'longestKill', 'matchDuration', 'maxPlace', 'numGroups', 'rankPoints', 'revives', 'rideDistance', 'roadKills', 'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints']\n",
      "+--------------------+------------+\n",
      "|            features|winPlacePerc|\n",
      "+--------------------+------------+\n",
      "|(24,[6,7,11,12,13...|      0.4444|\n",
      "|(24,[2,6,11,12,13...|        0.64|\n",
      "|(24,[0,2,6,11,12,...|      0.7755|\n",
      "+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark ml model to predict the winPlacePerc\n",
    "# https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "all_cols = df_train.columns\n",
    "all_cols.remove('winPlacePerc')\n",
    "print(all_cols)\n",
    "vectorAssembler = VectorAssembler(inputCols = all_cols, outputCol = 'features')\n",
    "vdf_train = vectorAssembler.transform(df_train)\n",
    "vdf_train = vdf_train.select(['features', 'winPlacePerc'])\n",
    "vdf_train.show(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model... without looking for best parameters\n",
      "Coefficients: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.649243249044998e-06,0.0,0.0]\n",
      "Intercept: 0.46500486339275177\n"
     ]
    }
   ],
   "source": [
    "splits = vdf_train.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='winPlacePerc', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "print(\"Training model... without looking for best parameters\")\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# print(\"Training model... looking for best parameters\")\n",
    "\n",
    "# test multiple parameters\n",
    "# paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]) .addGrid(lr.fitIntercept, [False, True]) .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]).addGrid(lr.maxIter, [10, 50, 100]).build() \n",
    "\n",
    "# # cross validation\n",
    "# crossval = CrossValidator(estimator=lr,\n",
    "#                             estimatorParamMaps=paramGrid,\n",
    "#                             evaluator=RegressionEvaluator(),\n",
    "#                             numFolds=3)  # use 3+ folds in practice\n",
    "\n",
    "# # Run cross-validation, and choose the best set of parameters.\n",
    "# cvModel = crossval.fit(train_df)\n",
    "\n",
    "# # Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "# predictions = cvModel.transform(test_df)\n",
    "\n",
    "# # Evaluate best model\n",
    "# evaluator = RegressionEvaluator(\n",
    "#     labelCol=\"winPlacePerc\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "# rmse = evaluator.evaluate(predictions)\n",
    "# print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------------------+\n",
      "|         prediction|winPlacePerc|            features|\n",
      "+-------------------+------------+--------------------+\n",
      "|0.46672036815100537|      0.2778|(24,[0,1,2,3,4,6,...|\n",
      "|0.46500486339275177|         0.1|(24,[0,1,2,3,5,6,...|\n",
      "| 0.4746063706443727|      0.6154|(24,[0,1,2,3,5,6,...|\n",
      "| 0.4687191306716683|      0.2143|(24,[0,1,2,3,5,6,...|\n",
      "| 0.4777381642146729|      0.6538|(24,[0,1,2,3,5,6,...|\n",
      "+-------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.301079\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"winPlacePerc\",\"features\").show(5)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"winPlacePerc\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(24,[2,6,11,12,13...|\n",
      "|[0.0,4.0,179.1,0....|\n",
      "|(24,[0,2,5,6,11,1...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------------------+--------------------+\n",
      "|         prediction|            features|\n",
      "+-------------------+--------------------+\n",
      "| 0.4689146184231902|(24,[2,6,11,12,13...|\n",
      "|0.47841638702607553|[0.0,4.0,179.1,0....|\n",
      "| 0.4702431372243494|(24,[0,2,5,6,11,1...|\n",
      "| 0.4770532921600213|(24,[2,6,11,12,13...|\n",
      "| 0.4847065711396721|[0.0,4.0,330.2,1....|\n",
      "+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the winPlacePerc for the test data\n",
    "all_cols = df_test.columns\n",
    "vectorAssembler = VectorAssembler(inputCols = all_cols, outputCol = 'features')\n",
    "vdf_test = vectorAssembler.transform(df_test)\n",
    "vdf_test = vdf_test.select(['features'])\n",
    "vdf_test.show(3)\n",
    "\n",
    "predictions = lr_model.transform(vdf_test)\n",
    "predictions.select(\"prediction\",\"features\").show(5)\n",
    "\n",
    "# save the predictions to a csv file\n",
    "predictions.select(\"prediction\").toPandas().to_csv('predictions.csv', index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac961c8513c096ff1f8d2e1b60b85bf4af3ed3048501804ac46c5e57531d9fe0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
